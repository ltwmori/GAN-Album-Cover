{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_album.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9QIokxDVYCDAcIb6TH/8n"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0SbKsNtaTHR",
        "outputId": "143fca2a-0b04-432a-f519-53305b8684bb"
      },
      "source": [
        "!pip install --upgrade tf_slim"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 8.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 4.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkMwNgRIW8qG"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import scipy.misc\n",
        "import tf_slim as slim"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rncT7xsZX3HG"
      },
      "source": [
        "#slim = tf.contrib.slim\n",
        "\n",
        "HEIGHT, WIDTH, CHANNEL = 64, 64, 3\n",
        "BATCH_SIZE = 64\n",
        "EPOCH = 5000\n",
        "version = 'newCover'\n",
        "new_path = './' + version"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M_xItMFYC7r"
      },
      "source": [
        "def lrelu(x, n, leak=0.2): \n",
        "    return tf.maximum(x, leak * x, name=n) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ayhiDBKYDrD"
      },
      "source": [
        "def process_data():   \n",
        "    current_dir = os.getcwd()\n",
        "    # parent = os.path.dirname(current_dir)\n",
        "    _dir = os.path.join(current_dir, 'data')\n",
        "    images = []\n",
        "    for each in os.listdir(_dir):\n",
        "        images.append(os.path.join(_dir,each))\n",
        "    # print images    \n",
        "    all_images = tf.convert_to_tensor(images, dtype = tf.string)\n",
        "    \n",
        "    images_queue = tf.train.slice_input_producer(\n",
        "                                        [all_images])\n",
        "                                        \n",
        "    content = tf.read_file(images_queue[0])\n",
        "    image = tf.image.decode_jpeg(content, channels = CHANNEL)\n",
        "    # sess1 = tf.Session()\n",
        "    # print sess1.run(image)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta = 0.1)\n",
        "    image = tf.image.random_contrast(image, lower = 0.9, upper = 1.1)\n",
        "    # noise = tf.Variable(tf.truncated_normal(shape = [HEIGHT,WIDTH,CHANNEL], dtype = tf.float32, stddev = 1e-3, name = 'noise')) \n",
        "    # print image.get_shape()\n",
        "    size = [HEIGHT, WIDTH]\n",
        "    image = tf.image.resize_images(image, size)\n",
        "    image.set_shape([HEIGHT,WIDTH,CHANNEL])\n",
        "    # image = image + noise\n",
        "    # image = tf.transpose(image, perm=[2, 0, 1])\n",
        "    # print image.get_shape()\n",
        "    \n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image / 255.0\n",
        "    \n",
        "    iamges_batch = tf.train.shuffle_batch(\n",
        "                                    [image], batch_size = BATCH_SIZE,\n",
        "                                    num_threads = 4, capacity = 200 + 3* BATCH_SIZE,\n",
        "                                    min_after_dequeue = 200)\n",
        "    num_images = len(images)\n",
        "\n",
        "    return iamges_batch, num_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc2FuiJ5YG8b"
      },
      "source": [
        "def generator(input, random_dim, is_train, reuse=False):\n",
        "    c4, c8, c16, c32, c64 = 512, 256, 128, 64, 32 # channel num\n",
        "    s4 = 4\n",
        "    output_dim = CHANNEL  # RGB image\n",
        "    with tf.variable_scope('gen') as scope:\n",
        "        if reuse:\n",
        "            scope.reuse_variables()\n",
        "        w1 = tf.get_variable('w1', shape=[random_dim, s4 * s4 * c4], dtype=tf.float32,\n",
        "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        b1 = tf.get_variable('b1', shape=[c4 * s4 * s4], dtype=tf.float32,\n",
        "                             initializer=tf.constant_initializer(0.0))\n",
        "        flat_conv1 = tf.add(tf.matmul(input, w1), b1, name='flat_conv1')\n",
        "         #Convolution, bias, activation, repeat! \n",
        "        conv1 = tf.reshape(flat_conv1, shape=[-1, s4, s4, c4], name='conv1')\n",
        "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n",
        "        act1 = tf.nn.relu(bn1, name='act1')\n",
        "        # 8*8*256\n",
        "        #Convolution, bias, activation, repeat! \n",
        "        conv2 = tf.layers.conv2d_transpose(act1, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                           name='conv2')\n",
        "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
        "        act2 = tf.nn.relu(bn2, name='act2')\n",
        "        # 16*16*128\n",
        "        conv3 = tf.layers.conv2d_transpose(act2, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                           name='conv3')\n",
        "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
        "        act3 = tf.nn.relu(bn3, name='act3')\n",
        "        # 32*32*64\n",
        "        conv4 = tf.layers.conv2d_transpose(act3, c32, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                           name='conv4')\n",
        "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
        "        act4 = tf.nn.relu(bn4, name='act4')\n",
        "        # 64*64*32\n",
        "        conv5 = tf.layers.conv2d_transpose(act4, c64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                           name='conv5')\n",
        "        bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n",
        "        act5 = tf.nn.relu(bn5, name='act5')\n",
        "        \n",
        "        #128*128*3\n",
        "        conv6 = tf.layers.conv2d_transpose(act5, output_dim, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                           name='conv6')\n",
        "        # bn6 = tf.contrib.layers.batch_norm(conv6, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn6')\n",
        "        act6 = tf.nn.tanh(conv6, name='act6')\n",
        "        return act6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfMyI4aEYKa4"
      },
      "source": [
        "def discriminator(input, is_train, reuse=False):\n",
        "    c2, c4, c8, c16 = 64, 128, 256, 512  # channel num: 64, 128, 256, 512\n",
        "    with tf.variable_scope('dis') as scope:\n",
        "        if reuse:\n",
        "            scope.reuse_variables()\n",
        "\n",
        "        #Convolution, activation, bias, repeat! \n",
        "        conv1 = tf.layers.conv2d(input, c2, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                 name='conv1')\n",
        "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training = is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope = 'bn1')\n",
        "        act1 = lrelu(conv1, n='act1')\n",
        "         #Convolution, activation, bias, repeat! \n",
        "        conv2 = tf.layers.conv2d(act1, c4, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                 name='conv2')\n",
        "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
        "        act2 = lrelu(bn2, n='act2')\n",
        "        #Convolution, activation, bias, repeat! \n",
        "        conv3 = tf.layers.conv2d(act2, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                 name='conv3')\n",
        "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
        "        act3 = lrelu(bn3, n='act3')\n",
        "         #Convolution, activation, bias, repeat! \n",
        "        conv4 = tf.layers.conv2d(act3, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "                                 name='conv4')\n",
        "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
        "        act4 = lrelu(bn4, n='act4')\n",
        "       \n",
        "        # start from act4\n",
        "        dim = int(np.prod(act4.get_shape()[1:]))\n",
        "        fc1 = tf.reshape(act4, shape=[-1, dim], name='fc1')\n",
        "      \n",
        "        \n",
        "        w2 = tf.get_variable('w2', shape=[fc1.shape[-1], 1], dtype=tf.float32,\n",
        "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        b2 = tf.get_variable('b2', shape=[1], dtype=tf.float32,\n",
        "                             initializer=tf.constant_initializer(0.0))\n",
        "\n",
        "        # wgan just get rid of the sigmoid\n",
        "        logits = tf.add(tf.matmul(fc1, w2), b2, name='logits')\n",
        "        # dcgan\n",
        "        acted_out = tf.nn.sigmoid(logits)\n",
        "        return logits #, acted_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCiIZCAjYNjF"
      },
      "source": [
        "def train():\n",
        "    random_dim = 100\n",
        "    \n",
        "    with tf.variable_scope('input'):\n",
        "        #real and fake image placholders\n",
        "        real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
        "        random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n",
        "        is_train = tf.placeholder(tf.bool, name='is_train')\n",
        "    \n",
        "    # wgan\n",
        "    fake_image = generator(random_input, random_dim, is_train)\n",
        "    \n",
        "    real_result = discriminator(real_image, is_train)\n",
        "    fake_result = discriminator(fake_image, is_train, reuse=True)\n",
        "    \n",
        "    d_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(real_result)  # This optimizes the discriminator.\n",
        "    g_loss = -tf.reduce_mean(fake_result)  # This optimizes the generator.\n",
        "            \n",
        "\n",
        "    t_vars = tf.trainable_variables()\n",
        "    d_vars = [var for var in t_vars if 'dis' in var.name]\n",
        "    g_vars = [var for var in t_vars if 'gen' in var.name]\n",
        "    trainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list=d_vars)\n",
        "    trainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list=g_vars)\n",
        "    # clip discriminator weights\n",
        "    d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]\n",
        "\n",
        "    \n",
        "    batch_size = BATCH_SIZE\n",
        "    image_batch, samples_num = process_data()\n",
        "    \n",
        "    batch_num = int(samples_num / batch_size)\n",
        "    total_batch = 0\n",
        "    sess = tf.Session()\n",
        "    saver = tf.train.Saver()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # continue training\n",
        "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
        "    ckpt = tf.train.latest_checkpoint('./model/' + version)\n",
        "    saver.restore(sess, save_path)\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "\n",
        "    print('total training sample num:%d' % samples_num)\n",
        "    print('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\n",
        "    print('start training...')\n",
        "    for i in range(EPOCH):\n",
        "        print(\"Running epoch {}/{}...\".format(i, EPOCH))\n",
        "        for j in range(batch_num):\n",
        "            print(j)\n",
        "            d_iters = 5\n",
        "            g_iters = 1\n",
        "\n",
        "            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
        "            for k in range(d_iters):\n",
        "                print(k)\n",
        "                train_image = sess.run(image_batch)\n",
        "                #wgan clip weights\n",
        "                sess.run(d_clip)\n",
        "                \n",
        "                # Update the discriminator\n",
        "                _, dLoss = sess.run([trainer_d, d_loss],\n",
        "                                    feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n",
        "\n",
        "            # Update the generator\n",
        "            for k in range(g_iters):\n",
        "                # train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
        "                _, gLoss = sess.run([trainer_g, g_loss],\n",
        "                                    feed_dict={random_input: train_noise, is_train: True})\n",
        "\n",
        "            # print 'train:[%d/%d],d_loss:%f,g_loss:%f' % (i, j, dLoss, gLoss)\n",
        "            \n",
        "        # save check point every 500 epoch\n",
        "        if i%500 == 0:\n",
        "            if not os.path.exists('./model/' + version):\n",
        "                os.makedirs('./model/' + version)\n",
        "            saver.save(sess, './model/' +version + '/' + str(i))  \n",
        "        if i%50 == 0:\n",
        "            # save images\n",
        "            if not os.path.exists(newPoke_path):\n",
        "                os.makedirs(newPoke_path)\n",
        "            sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
        "            imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n",
        "            # imgtest = imgtest * 255.0\n",
        "            # imgtest.astype(np.uint8)\n",
        "            save_images(imgtest, [8,8] ,newPoke_path + '/epoch' + str(i) + '.png')\n",
        "            \n",
        "            print('train:[%d],d_loss:%f,g_loss:%f' % (i, dLoss, gLoss))\n",
        "    coord.request_stop()\n",
        "    coord.join(threads)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54i20OQWYRk3"
      },
      "source": [
        "# def test():\n",
        "    # random_dim = 100\n",
        "    # with tf.variable_scope('input'):\n",
        "        # real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
        "        # random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n",
        "        # is_train = tf.placeholder(tf.bool, name='is_train')\n",
        "    \n",
        "    # # wgan\n",
        "    # fake_image = generator(random_input, random_dim, is_train)\n",
        "    # real_result = discriminator(real_image, is_train)\n",
        "    # fake_result = discriminator(fake_image, is_train, reuse=True)\n",
        "    # sess = tf.InteractiveSession()\n",
        "    # sess.run(tf.global_variables_initializer())\n",
        "    # variables_to_restore = slim.get_variables_to_restore(include=['gen'])\n",
        "    # print(variables_to_restore)\n",
        "    # saver = tf.train.Saver(variables_to_restore)\n",
        "    # ckpt = tf.train.latest_checkpoint('./model/' + version)\n",
        "    # saver.restore(sess, ckpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ1koBJOYUPc"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train()\n",
        "    # test()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
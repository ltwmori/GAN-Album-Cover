{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gan_V3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9faqQB5i2-6",
        "outputId": "0b6b3822-b755-4d28-f528-a2d864171b40"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2mG79Ira3CJ"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import scipy.misc\n",
        "import tf_slim as slim\n",
        "import keras\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA7kYMcw6AiF"
      },
      "source": [
        "latent_dim = 100\n",
        "HEIGHT, WIDTH, CHANNEL = 64, 64, 3\n",
        "BATCH_SIZE = 128\n",
        "EPOCH = 10000"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS2QFZ7HrN1T",
        "outputId": "d77ac163-896b-4c51-f559-3dd64fd03142"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhTrVWFCqwrs"
      },
      "source": [
        "''''import pathlib\n",
        "data_dir = pathlib.Path(\"gdrive/MyDrive/projects/images/\")''''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE9ZgHWwrSDz",
        "outputId": "2573d001-6e35-4d1c-dd8f-42be93d32e39"
      },
      "source": [
        "'''image_count = len(list(data_dir.rglob('*.png')))\n",
        "print(image_count)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56tgoVwCdgSn"
      },
      "source": [
        "# **Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJZyu2zNdm6W"
      },
      "source": [
        "def loss_generator(logit_fake):\n",
        "    \"\"\"\n",
        "    loss function for generator.\n",
        "    \"\"\"\n",
        "    return tf.math.negative(tf.math.reduce_mean(tf.math.log(logit_fake)))\n",
        "\n",
        "\n",
        "def loss_discriminator(logit_real, logit_fake):\n",
        "    \"\"\"\n",
        "    loss function for discriminator.\n",
        "    \"\"\"\n",
        "    loss_real = tf.math.negative(tf.math.reduce_mean(tf.math.log(logit_real)))\n",
        "    loss_fake = tf.math.negative(tf.math.reduce_mean(tf.math.log(1. - logit_fake)))\n",
        "    return loss_real + loss_fake"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLTE9S2JopTw"
      },
      "source": [
        "# **Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NmsRGeuwRMu"
      },
      "source": [
        "def Generator():\n",
        "  generator_input = keras.Input(shape = (latent_dim,))\n",
        "\n",
        "  x = keras.layers.Dense(16384, activation = \"linear\")(generator_input)\n",
        "  x = keras.layers.Reshape((4,4,1024))(x)\n",
        "\n",
        "  x = keras.layers.Conv2DTranspose(512, 4, strides = 2, padding='same', activation = 'relu')(x)\n",
        "  x = keras.layers.Conv2DTranspose(256, 4, strides = 2, padding = 'same', activation = 'relu')(x)\n",
        "  x = keras.layers.Conv2DTranspose(128, 4, strides = 2, padding = 'same', activation = 'relu')(x)\n",
        "  x = keras.layers.Conv2DTranspose(3, 4, strides = 2, padding = 'same', activation = 'tanh')(x)\n",
        "\n",
        "  model = keras.models.Model(inputs = generator_input, outputs = x)\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5DSwFFkouzs"
      },
      "source": [
        "# **Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1uN5S-e0Gst"
      },
      "source": [
        "def Discriminator():\n",
        "  discriminator_input = keras.layers.Input(shape = (HEIGHT, WIDTH, CHANNEL))\n",
        "  x = keras.layers.Conv2D(128, 4, strides = 2, padding = \"same\")(discriminator_input)\n",
        "  x = keras.layers.LeakyReLU(0.2)(x)\n",
        "  x = keras.layers.Conv2D(256, 4, strides = 2, padding = \"same\")(x)\n",
        "  x = keras.layers.LeakyReLU(0.2)(x)\n",
        "  x = keras.layers.Conv2D(512, 4, strides = 2, padding = \"same\")(x)\n",
        "  x = keras.layers.LeakyReLU()(x)\n",
        "  x = keras.layers.Conv2D(1024, 4, strides = 2, padding = \"same\")(x)\n",
        "  x = keras.layers.LeakyReLU()(x)\n",
        "\n",
        "  x = keras.layers.Reshape((1,16384), input_shape=(4,1024))(x)\n",
        "\n",
        "  x = keras.layers.Dense(1, activation = 'linear')(x)\n",
        "  x = keras.layers.Dense(5, activation = 'linear')(x)\n",
        "  x = keras.layers.Dense(2, activation = 'linear')(x)\n",
        "\n",
        "  model = keras.models.Model(inputs = discriminator_input, outputs = x)\n",
        "  return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw6uJLMrev5H"
      },
      "source": [
        "# **Create gen and dis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCgpKgj-c_2P"
      },
      "source": [
        "def create_generator():\n",
        "    #creates generator, its optimizer (Adam) and checkpoint.\n",
        "\n",
        "    generator = Generator()\n",
        "    generator_optimizer = Adam(lr=0.002, beta_1=0.5)\n",
        "    generator_checkpoint = tf.train.Checkpoint(optimizer=generator_optimizer, model=generator)\n",
        "\n",
        "    return generator, generator_optimizer, generator_checkpoint"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcev3DICeIZX"
      },
      "source": [
        "def create_discriminator():\n",
        "    #creates discriminator, its optimizer (Adam) and checkpoint.\n",
        "\n",
        "    discriminator = Discriminator()\n",
        "    discriminator_optimizer = Adam(lr=0.001, beta_1=0.5)\n",
        "    discriminator_checkpoint = tf.train.Checkpoint(optimizer=discriminator_optimizer, model=discriminator)\n",
        "\n",
        "    return discriminator, discriminator_optimizer, discriminator_checkpoint"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du7zwLKae3yt"
      },
      "source": [
        "# **Save images function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUT7bPEle1w1"
      },
      "source": [
        "def generate_print_save(model, input, epoch):\n",
        "    \"\"\"\n",
        "    generates, prints and saves 9 images for a given input noise of shape [9, noise_size],\n",
        "    where noise_size is globally defined.\n",
        "    \"\"\"\n",
        "    prediction = model(input, training=False)\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for i in range(9):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(prediction[i])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch+1))\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnWZlg4ygprf"
      },
      "source": [
        "\n",
        "def read_images(data_dir):\n",
        "    \"\"\"\n",
        "    reads images from data_dir into a numpy array of shape\n",
        "    (number of images, height, width, number of channels (=3 for rgb)).\n",
        "    pixels of each image are normalized (in the interval [-1, 1]).\n",
        "    \"\"\"\n",
        "    images = list()\n",
        "    for file_name in data_dir:\n",
        "        image = Image.open(file_name)\n",
        "        image = np.asarray(image)\n",
        "        images.append(image)\n",
        "\n",
        "    return (np.asarray(images) - 127.5) / 127.5\n",
        "    \n",
        "\n",
        "\n",
        "def print_images(images):\n",
        "    \"\"\"\n",
        "    prints first 9 images (in 3 columns and 3 rows) from images numpy array.\n",
        "    \"\"\"\n",
        "    for i in range(9):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE5pl1j-6o8C"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwDcL8-b8DIL"
      },
      "source": [
        "def train_DCGAN(train_set, batch_size, epochs):\n",
        "    \"\"\"\n",
        "    trains the globally defined generator and discriminator.\n",
        "    \"\"\"\n",
        "    # train set size\n",
        "    train_size = train_set.shape[0]\n",
        "\n",
        "    # the size of noise vector is given globally\n",
        "    noise_size = latent_dim\n",
        "\n",
        "    # number of mini batches\n",
        "    m = train_size // batch_size\n",
        "\n",
        "    # partition the training set to mini batches\n",
        "    train_batches = np.split(train_set, [k * batch_size for k in range(1, m)])\n",
        "\n",
        "\n",
        "    # prefixes for the checkpoints of the generator and discriminator\n",
        "    generator_prefix = os.path.join('./generator', 'ckpt')\n",
        "    discriminator_prefix = os.path.join('./discriminator', 'ckpt')\n",
        "\n",
        "    # lists to record costs of the generator and discriminator at every 10 epochs\n",
        "    generator_costs = list()\n",
        "    discriminator_costs = list()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # initiate costs of the generator and discriminator at the current epoch to zeros\n",
        "        generator_cost = 0\n",
        "        discriminator_cost = 0\n",
        "\n",
        "        for batch in train_batches:\n",
        "            # random noise for the current mini batch\n",
        "            noise = tf.random.normal([batch_size, noise_size])\n",
        "\n",
        "            # watch trainable variables for the loss functions of the generator and discriminator\n",
        "            with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
        "                fake_images = generator(noise, training=True) # the generator generates fake images\n",
        "\n",
        "                # the discriminator computes logits (probabilites) of images for being real\n",
        "                logit_fake = discriminator(fake_images, training=True)\n",
        "                logit_real = discriminator(batch, training=True)\n",
        "\n",
        "                # loss functions for the generator and discriminator\n",
        "                generator_loss = loss_generator(logit_fake)\n",
        "                discriminator_loss = loss_discriminator(logit_real, logit_fake)\n",
        "\n",
        "            # compute gradients and perform one step gradient descend\n",
        "            generator_Grads = generator_tape.gradient(generator_loss, generator.trainable_variables)\n",
        "            generator_optimizer.apply_gradients(zip(generator_Grads, generator.trainable_variables))\n",
        "            discriminator_Grads = discriminator_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
        "            discriminator_optimizer.apply_gradients(zip(discriminator_Grads, discriminator.trainable_variables))\n",
        "\n",
        "            # record costs of the generator and discriminator at every 10 epochs\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                fake_images = generator(noise, training=False)\n",
        "                logit_fake = discriminator(fake_images, training=False)\n",
        "                logit_real = discriminator(batch, training=False)\n",
        "                generator_cost += loss_generator(logit_fake).numpy() / m\n",
        "                discriminator_cost += loss_discriminator(logit_real, logit_fake).numpy() / m\n",
        "\n",
        "        # save checkpoints at every 10 epochs\n",
        "        # also print and save 9 randomly generated images at every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            generator_checkpoint.save(file_prefix=generator_prefix)\n",
        "            discriminator_checkpoint.save(file_prefix=discriminator_prefix)\n",
        "\n",
        "            generator_costs.append(generator_cost)\n",
        "            discriminator_costs.append(discriminator_cost)\n",
        "\n",
        "            display.clear_output(wait=True)\n",
        "            print('Epoch: {}'.format(epoch+1))\n",
        "            print('Generator loss: {}'.format(generator_loss))\n",
        "            print('Discriminator loss: {}'.format(discriminator_loss))\n",
        "            noise = tf.random.normal([9, noise_size])\n",
        "            generate_print_save(generator, noise, epoch)\n",
        "\n",
        "    # plot the learning curves of the generator and discriminator\n",
        "    plt.plot(np.squeeze(generator_costs))\n",
        "    plt.plot(np.squeeze(discriminator_costs))\n",
        "    plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myms6Co_fICm"
      },
      "source": [
        "# **Download images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPtBdPOsfHQ9"
      },
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path(\"gdrive/MyDrive/projects/images/pop\")\n",
        "train_set = read_images(data_dir.rglob('*.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hc8FbkQfUiu"
      },
      "source": [
        "# let us look at few images from the dataset\n",
        "print_images(images=train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfAqC_IGfeK-"
      },
      "source": [
        "generator, generator_optimizer, generator_checkpoint = create_generator()\n",
        "discriminator, discriminator_optimizer, discriminator_checkpoint = create_discriminator()\n",
        "\n",
        "# train generator and discriminator\n",
        "train_DCGAN(train_set, batch_size=BATCH_SIZE, epochs=EPOCH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}